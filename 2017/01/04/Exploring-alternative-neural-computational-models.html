<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Exploring alternative neural computational models</title>
    <meta name="description" content="" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="https://raghakot.github.io/favicon.ico">

    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:400,700,400italic,700italic|Open+Sans:400italic,700italic,700,400">
    <link rel="stylesheet" type="text/css" href="//raghakot.github.io/themes/roon/assets/css/screen.css?v=1484257967384" />

    <link rel="canonical" href="https://raghakot.github.io/2017/01/04/Exploring-alternative-neural-computational-models.html" />
    <meta name="referrer" content="origin" />
    
    <meta property="og:site_name" content="Ragha&#x27;s Blog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Exploring alternative neural computational models" />
    <meta property="og:description" content="Despite different variations of neural networks architectures, the computational model of a neuron hasn&amp;#8217;t changed since inception. Every neuron has \(n\) incoming inputs \(X &#x3D; (x_{1}, x_{2}, &amp;#8230;&amp;#8203;, x_{n})\) with weights \(W &#x3D; (w_{1}, w_{2}, &amp;#8230;&amp;#8203;, w_{n})\). A neuron then computes \(W." />
    <meta property="og:url" content="https://raghakot.github.io/2017/01/04/Exploring-alternative-neural-computational-models.html" />
    <meta property="article:tag" content="deep learning" />
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Exploring alternative neural computational models" />
    <meta name="twitter:description" content="Despite different variations of neural networks architectures, the computational model of a neuron hasn&amp;#8217;t changed since inception. Every neuron has \(n\) incoming inputs \(X &#x3D; (x_{1}, x_{2}, &amp;#8230;&amp;#8203;, x_{n})\) with weights \(W &#x3D; (w_{1}, w_{2}, &amp;#8230;&amp;#8203;, w_{n})\). A neuron then computes \(W." />
    <meta name="twitter:url" content="https://raghakot.github.io/2017/01/04/Exploring-alternative-neural-computational-models.html" />
    
    <script type="application/ld+json">
null
    </script>

    <meta name="generator" content="HubPress" />
    <link rel="alternate" type="application/rss+xml" title="Ragha&#x27;s Blog" href="https://raghakot.github.io/rss/" />
</head>
<body class="post-template tag-deep-learning  noimage">

    


    <article role="main" class="">
        <header>
            <a href="https://raghakot.github.io" id="home_link">Â«</a>
            <div class="meta"><time datetime="2017-01-03"><a href="/">January 03, 2017</a></time> <span class="count" id="js-reading-time"></span></div>
            <h1>Exploring alternative neural computational models</h1>
        </header>

        <div class="text" id="js-post-content">
            <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Despite different variations of neural networks architectures, the computational model of a neuron hasn&#8217;t changed since inception. Every neuron has \(n\) incoming inputs \(X = (x_{1}, x_{2}, &#8230;&#8203;, x_{n})\) with weights \(W = (w_{1}, w_{2}, &#8230;&#8203;, w_{n})\). A neuron then computes \(W.X = \sum_{i=0}^{n}w_{i}.x_{i}\), forwards it through some nonlinearity like sigmoid or ReLU to generate the output<sup class="footnote">[<a id="_footnoteref_1" class="footnote" href="#_footnote_1" title="View footnote.">1</a>]</sup>.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="https://raghakot.github.io/images/alt_neural1/neuron_model.jpeg" alt="neuron_model" width="400">
</div>
<div class="title">Figure 1. Computation model of a neuron</div>
</div>
<div class="paragraph">
<p><br></p>
</div>
<div class="paragraph">
<p>As far as i am aware, all architectures build on this fundamental computational model. Let us examine what the computation is conceptually doing in a step by step fashion.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Each input component \(x_{i}\) is being magnified or diminished when multiplied with a scaling factor \(w_{i}\). This can be interpreted as enhancing or diminishing the contribution of some pattern component \(x_{i}\) to the output decision. Think of these weights as <em>knobs</em> that range from \([-\infty, +\infty]\). The task of learning is to <em>tune</em> these knobs to the correct value.</p>
</li>
<li>
<p>The computation \(W.X\) is then enhancing/diminishing various input components of vector \(X\). In terms of linear algebra, the dot product of \(W\) and \(X\) can be interpreted as computing similarity. Consider \(X = (x_{1}, x_{2})\) and \(W = (w_{1}, w_{2})\). If you imagine plotting these vectors on a 2D graph paper, \(\frac{W.X}{|W||X|}\) is the cosine of angle between these two vectors. When these two vectors align (point in the same direction), the value of \(W.X\) is maximized indicating high degree of similarity. From this point of view, neuron is fundamentally a pattern matching unit which outputs a large value when it matches a specific pattern (encoded by weights) in the input<sup class="footnote">[<a id="_footnoteref_2" class="footnote" href="#_footnote_2" title="View footnote.">2</a>]</sup>.</p>
</li>
<li>
<p>In a complex neural network, every neuron is matching the input against some template encoded via weights and forwarding that result to the subsequent layers. In case of image recognition, the first layer neurons might match whether the input contains vertical edge, horizontal edge and so on. The circle detection neuron might use various edge matching computation results from previous layers to detect the shape patterns.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>So far so good. <em>What is the purpose of activation function?</em> To understand the motivation, consider the geometric perspective of the computation through the lens of linear algebra.</p>
</div>
<div class="paragraph">
<p>\( W.X = \begin{bmatrix} w_{1} \\ w_{2} \\ \vdots \\ w_{n} \end{bmatrix} \begin{bmatrix} x_{1} &amp; x_{2} &amp; \cdots &amp; x_{n} \end{bmatrix} \)</p>
</div>
<div class="paragraph">
<p>Geometrically, this can be interpreted as a linear transformation of \(X\). Additionally, there is a bias term to shift the origin. So, the computation \(W.X + b\) can be interpreted as an affine transformation. Without an non-linear activation function, multiple linear transformations within each layer \(W_{L}\) can be condensed into a single layer with \(W = \prod_{L}W_{L}\). A single layered linear neural network is pretty limited in its representational power.</p>
</div>
<div class="paragraph">
<p>Lets put all this together to interpret what a multi-layered neural network might be doing<sup class="footnote">[<a id="_footnoteref_3" class="footnote" href="#_footnote_3" title="View footnote.">3</a>]</sup>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Suppose we input a \(100 \times 100\) image to a vggnet. The input tensor \(X\) can be thought of as a vector with 10000 basis. Each basis is representing some positional component in an image.</p>
</li>
<li>
<p>We know that the very first conv layer learns gabor filter like edge detection weight templates. Lets assume that the first convolutional layer filter generates \(100 \times 100\) output (assuming appropriate padding). This can be seen as <em>transforming</em> input from positional basis vector space to edge-like basis vector space. Instead of measuring the pixel intensity, the new vector space measures the similarity of the positional input patch with respect to a edge-detection templates (\(3 \times 3\) conv filter weights). Extrapolating on this notion, every layer <em>transforms</em> the data into a more meaningful basis vector space, eventually leading to basis vectors comprising of output categories.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_motivation">Motivation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the current computational model, the output of a neuron is different even though \(X\) and \(W\) perfectly align with each other but differ in magnitudes. As each \(w_{i}\) has range \([-\infty, \infty]\), backprop is essentially searching for this weight vector spanning all of the weight vector space.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="https://raghakot.github.io/images/alt_neural1/vector_similarity.png" alt="vector_similarity" width="300">
</div>
<div class="title">Figure 2. Similarity between vectors X and W</div>
</div>
<div class="paragraph">
<p><br></p>
</div>
<div class="paragraph">
<p>If we view a neuron as fundamental template matching unit, then various magnitude (length) of \(X\) and \(W\) should yield the same output. If we constrain \(W\) to be a unit vector (\(|W| = 1\)), then backprop would only need to search along points on a hypersphere of unit radius. Although the hypersphere contains infinitely many points, with sufficient discretization, the search space intuitively <em>feels</em> a lot smaller than the entire weight vector space.</p>
</div>
<div class="paragraph">
<p>Considering that weight sharing (a form on constraint) in conv-nets led to huge improvements, constraining seems like a reasonable approach. Weight regularization - a form of constraint - penalizes large \(|W|\) and vaguely fits the idea of encouraging weight updates to explore points along the hypersphere.</p>
</div>
<div class="paragraph">
<p>I think that in general, constraining as a research direction is largely unexplored. For example, it might be interesting to try and constrain conv filters to be as <em>distinct</em> and <em>diverse</em> and possible. I will follow up on these investigations in a future blog.</p>
</div>
<div class="paragraph">
<p>Getting back to the topic at hand, there are several options for constraining \(|W| = 1\).</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Penalize when \(|W|\) deviates from 1 as a regularization loss.</p>
</li>
<li>
<p>Represent \(W\) in parametric form. Each \(w_{i}\) can be calculated using n-dim <a href="https://en.wikipedia.org/wiki/N-sphere#Spherical_coordinates">spherical coordinates</a>.</p>
</li>
<li>
<p>Instead of computing \(W.X\), compute \(\frac{W}{|W|} \times X\). Normalizing \(W\) ensures that the output does not change due to scaling. Consequently, the gradient of output with respect to \(W\) can only exist if \(W\) changes along the unit hypersphere.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_experimental_setup">Experimental Setup</h2>
<div class="sectionbody">
<div class="paragraph">
<p>I explored option 3 as it was the simplest to implement. The architecture is a simplified version of vggnet comprising of \(3 \times 3\) convolutions with ReLU activation and max pooling. I used cifar10 dataset augmented with 10% random shifts along image rows/cols along with a 50% chance of horizontal flip. <code>random_seed = 1337</code> was used to get consistent and reproducible results across trials.</p>
</div>
<div class="paragraph">
<p>The model has 1,250,858 parameters and trained for 50 epochs with a batch size of 32 using categorical cross-entropy loss with Adam optimizer.</p>
</div>
<div class="paragraph">
<p>\(W_{norm}\) is calculated as:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># 1e-8 is used to prevent division by 0
W_norm = W / (tf.sqrt(tf.reduce_sum(tf.square(W), axis=[0, 1, 2], keep_dims=True)) + 1e-8)</code></pre>
</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="https://raghakot.github.io/images/alt_neural1/model.png" alt="test_model" width="300">
</div>
<div class="title">Figure 3. Test model</div>
</div>
<div class="paragraph">
<p><br></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_discussion">Discussion</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Final loss and accuracy values on validation set are summarized in the table.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 1. Convergence results after 50 epochs</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"></th>
<th class="tableblock halign-left valign-top">Old Model</th>
<th class="tableblock halign-left valign-top">New Model</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">val_loss</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.8257</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.6156</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">val_accuracy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.7165</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.7935</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>As hypothesized, constraining weight vector to a unit hypersphere speeds up training (see convergence graphs).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="https://raghakot.github.io/images/alt_neural1/convergence.png" alt="convergence_graphs" width="800">
</div>
<div class="title">Figure 4. Convergence graphs for loss and accuracy on validation set for <span class="aqua">old</span> and <span class="red">new</span> computational models</div>
</div>
<div class="paragraph">
<p><br></p>
</div>
<div class="paragraph">
<p>Its neat when small changes like these make a significant difference. More experimentation is required to see if this improves over base model when run all the way until convergence. It is also worth experimenting with state of the art models such as the <a href="https://arxiv.org/pdf/1412.6806.pdf">All convolutional neural network</a> to see if makes any difference there.</p>
</div>
<div class="paragraph">
<p>We used <code>ReLU</code> which effectively attenuates negative values. This limits the neuron to only communicate information when the angle between \(X\) and \(W\) lies between \([-\frac{\pi}{2}, \frac{\pi}{2}]\). Perhaps it is useful if a neuron could also communicate the <em>lack of</em> similarity or the <em>inverse</em> of weight template information. For example, the lack of a specific stripe pattern might increase the networks confidence that the output is more likely to be one cat species over another.</p>
</div>
<div class="paragraph">
<p>One way to remedy this problem might be to use an activation function that allows negative values. A quick experiment with <code>ELU</code> activation, however, did not yield any significant improvement.</p>
</div>
</div>
</div>
<div id="footnotes">
<hr>
<div class="footnote" id="_footnote_1">
<a href="#_footnoteref_1">1</a>. Technically, bias is involved, but i am excluding it to keep the discussion focused.
</div>
<div class="footnote" id="_footnote_2">
<a href="#_footnoteref_2">2</a>. The correct weight vectors are learned using backpropogation.
</div>
<div class="footnote" id="_footnote_3">
<a href="#_footnoteref_3">3</a>. This is my own interpretation and might as well be incorrect.
</div>
</div>
        </div>

        <menu>
            <a href="" id="btn_share" class="btn" title="Share">
                <span aria-hidden="true" data-icon="S"></span>
                <strong>Share</strong>
            </a>
            <a href="http://twitter.com/share?text=Exploring%20alternative%20neural%20computational%20models&url=https://raghakot.github.io/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" id="btn_comment" class="btn" target="_blank">
                <span aria-hidden="true" data-icon="C"></span> Comment on Twitter
            </a>
        </menu>


        <footer class="post-footer" role="contentinfo">

            <div class="vcard">
                <a href="https://raghakot.github.io/rss" id="btn_feed" class="btn" title="Feed" target="_blank">
                    <span aria-hidden="true" data-icon=")"></span>
                    <strong>Feed</strong>
                </a>

                <a href="https://raghakot.github.io/author/raghakot/" class="photo">
                    <span style="background-image: url('https://avatars.githubusercontent.com/u/15642444?v&#x3D;3');">
                        <img src="https://avatars.githubusercontent.com/u/15642444?v&#x3D;3" alt="Raghavendra Kotikalapudi">
                    </span>
                </a>

                <div class="details">
                    <h4><a href="https://raghakot.github.io/author/raghakot/" class="url n">Raghavendra Kotikalapudi</a></h4>
                    Seattle WA<br>
                    
                </div>
            </div>

            <div id="user_bio">
                <div class="inner">
                    
                </div>
            </div>

        </footer>




    <section class="post-comments">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
      var disqus_shortname = 'raghakot-github-io'; // required: replace example with your forum shortname
      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
      </script>
      <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </section>


    </article>

    <div id="share_modal">
        <div class="wrap">
            <div class="inner">
                <header>
                    Share
                    <a href="" class="close" title="Close">&times;</a>
                </header>

                <div class="roon-share-links">
                    <a href="https://twitter.com/share" class="twitter-share-button" data-dnt="true">Tweet</a>
                    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

                    <div id="fb-elems">
                        <div id="fb-root"></div>
                        <script>(function(d, s, id) {
                        var js, fjs = d.getElementsByTagName(s)[0];
                        if (d.getElementById(id)) return;
                        js = d.createElement(s); js.id = id;
                        js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=463438580397968";
                        fjs.parentNode.insertBefore(js, fjs);
                        }(document, 'script', 'facebook-jssdk'));</script>
                        <div class="fb-like" data-send="false" data-layout="button_count" data-width="110" data-show-faces="false" data-font="arial"></div>
                    </div>

                    <div id="pinit-btn">
                        <a href="//pinterest.com/pin/create/button/?url=https://raghakot.github.io/&amp;description=Exploring%20alternative%20neural%20computational%20models-Ragha's%20Blog " data-pin-do="buttonPin" data-pin-config="beside"><img src="//assets.pinterest.com/images/pidgets/pin_it_button.png"></a>
                        <script type="text/javascript" src="//assets.pinterest.com/js/pinit.js"></script>
                    </div>
                </div>
            </div>
        </div>
    </div>






    <script>

            function get_text(el) {
                ret = "";
                var length = el.childNodes.length;
                for(var i = 0; i < length; i++) {
                    var node = el.childNodes[i];
                    if(node.nodeType != 8) {
                        ret += node.nodeType != 1 ? node.nodeValue : get_text(node);
                    }
                }
                return ret;
            }
            function reading_time () {
                var post_content = document.getElementById('js-post-content');
                if (post_content) {
                    var words = get_text(post_content),
                        count = words.split(/\s+/).length,
                        read_time = Math.ceil((count / 150)),
                        read_time_node = document.createTextNode(read_time + ' min read');
                    document.getElementById('js-reading-time').appendChild(read_time_node);
                }
            }

        function no_schema_links () {
            var links = document.querySelectorAll('.js-remove-domain-schema');
            if (links) {
                for (i = 0; i < links.length; ++i) {
                    var link = links[i],
                        text = link.innerHTML,
                        no_schema = text.replace(/.*?:\/\//g, "");
                    link.innerHTML = no_schema;
                }
            }
        }

        window.onload = function () {
            no_schema_links();

            reading_time();
        }
    </script>

    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script> <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js?v="></script> <script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.9.0/moment-with-locales.min.js?v="></script> <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js?v="></script> 
      <script type="text/javascript">
        jQuery( document ).ready(function() {
          // change date with ago
          jQuery('ago.ago').each(function(){
            var element = jQuery(this).parent();
            element.html( moment(element.text()).fromNow());
          });
        });

        hljs.initHighlightingOnLoad();
      </script>

        <script>
            $(function(){
                var share_modal = $("#share_modal"),
                    update_social_links = true;

                $("#btn_share").click(function(){
                    var that = $(this);
                    share_modal.fadeIn(200);
                    return false;
                });

                share_modal.click(function(e){
                    if (e.target.className == "wrap" || e.target.id == "share_modal") {
                        share_modal.fadeOut(200);
                    }
                    return false;
                });

                share_modal.find("div.inner > header > a.close").click(function(){
                    share_modal.fadeOut(200);
                    return false;
                });
            });
        </script>


    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-78195880-1', 'auto');
    ga('send', 'pageview');

    </script>

</body>
</html>

= SimNeuron - A simplified neural computational model.

== Overview

Despite different variations of neural networks architectures such as LSTMs, ConvNets, endcoder-decoder architectures and so on, the computational model of a neuron hasn't changed since inception. Every neuron has \(n\) incomming inputs \(X = (x_{1}, x_{2}, ..., x_{n})\) with weights \(W = (w_{1}, w_{2}, ..., w_{n})\). A neuron then computes \(W.X = \sum_{i=0}^{n}w_{i}.x_{i}\) and then uses some nonlinearity like sigmoid or ReLU to generate the output. All architectures build on this fundamental computational model. Let us examine what the computation is conceptually doing in a step by step fashion.

1. Each input component \(x_{i}\) is being magnified or diminished when multiplied with a scaling factor \(w_{i}\). This can be interpreted as enhancing or diminishing the contribution of some pattern component \(x_{i}\) to the output decision. Think of these weights as _knobs_ that range from \([-\inf, +\inf]\). The task of learning is to _tune_ these knobs to the correct value.
2. The computation \(W.X\) is then enhancing/diminishing various input components of \(X\). In terms of linear algebra, the dot product of \(W\) and \(X\) can be interpeted as computing similarity. Consider \(X = (x_{1}, x_{2})\) and \(W = (w_{1}, w_{2})\). If you imagine plotting these vectors on a 2D graph paper, \(\frac{W.X}{|W||X|}\) is the cosine of angle between these two vectors. When these two vectors align, but irrespective of magnitude, the output value \(W.X\) is maximized indicating max similarility. From this point of view, neuron is fundametally a pattern matching unit which outputs a max value when it recognizes a specific pattern (encoded by weights). The weight pattern is learned via gradient descent.
3. In a complex neural network, every neuron is matching the input with some pattern and forwarding that result to the subsequent layers. In case of image recognition, the earlier layer neurons might match whether the input contains vertical edge, horizontal edge and so on. The circle detection neuron might use various edge computation results from previous layers to detect the circle pattern. In this manner, the later layers might learn to detect complex patterns like eyes, nose, ears etc.

So far so good. What is the purpose of activation function? To understand the motivation, we need to consider the computation from the _layer_ perspective. A _layer_ has \(X\) as the input an \(Y\) as the output. Using linear algebra, the entire computation can be represented as \(Y = Act(W \cross X + b)\), where \(Act(...)\) is the activation function. \(W \cross X\) can be interpreted as performing a linear transformation on X. The bias \(b\) adds addtional representational power by shifting the origin. Without \(Act\) multiple linear transformations within each layer \(W_{L}\) can be condensed into a single layer with \(W = \prod_{L}W_{L}\). A single layered linear neural network is pretty limited.


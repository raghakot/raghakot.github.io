= SimNeuron - A simplified neural computational model.

== Overview

Despite different variations of neural networks architectures such as LSTMs, ConvNets, endcoder-decoder architectures and so on, the computational model of a neuron hasn't changed since inception. Every neuron has \(n\) incomming inputs \(X = (x_{1}, x_{2}, ..., x_{n})\) with weights \(W = (w_{1}, w_{2}, ..., w_{n})\). A neuron then computes \(W.X = \sum_{i=0}^{n}w_{i}.x_{i}\) and then uses some nonlinearity like sigmoid or ReLU to generate the output. footnote:[Technically, bias is involved, but i am excluding it to keep the discussion focused]

[.text-center]
.Computation model of a neuron
image::sim_neuron/neuron_model.jpeg[neuron_model]
{empty} +

All architectures build on this fundamental computational model. Let us examine what the computation is conceptually doing in a step by step fashion.

* Each input component \(x_{i}\) is being magnified or diminished when multiplied with a scaling factor \(w_{i}\). This can be interpreted as enhancing or diminishing the contribution of some pattern component \(x_{i}\) to the output decision. Think of these weights as _knobs_ that range from \([-\inf, +\inf]\). The task of learning is to _tune_ these knobs to the correct value.

* The computation \(W.X\) is then enhancing/diminishing various input components of vector \(X\). In terms of linear algebra, the dot product of \(W\) and \(X\) can be interpeted as computing similarity. Consider \(X = (x_{1}, x_{2})\) and \(W = (w_{1}, w_{2})\). If you imagine plotting these vectors on a 2D graph paper, \(\frac{W.X}{|W||X|}\) is the cosine of angle between these two vectors. When these two vectors align (point in the same direction), the value of \(W.X\) is maximized indicating high degree of similarity. From this point of view, neuron is fundametally a pattern matching unit which outputs a large value when it matches a specific pattern (encoded by weights) in the input. footnote:[The correct weight vectors are learned using backpropogation.]

* In a complex neural network, every neuron is matching the input with somepattern and forwarding that result to the subsequent layers. In case of image recognition, the earlier layer neurons might match whether the input contains vertical edge, horizontal edge and so on. The circle detection neuron might use various edge computation results from previous layers to detect the circle pattern. In this manner, the later layers might learn to detect complex patterns like eyes, nose, ears etc.

So far so good. What is the purpose of activation function? To understand the motivation, we need to consider the computation from the _layer_ perspective. A _layer_ has \(X\) as the input an \(Y\) as the output. Using linear algebra, the entire computation can be represented as \(Y = Act(W \times X + b)\), where \(Act(...)\) is the activation function. \(W \times X\) can be interpreted as performing a linear transformation on X. The bias \(b\) adds addtional representational power by shifting the origin. Without \(Act\) multiple linear transformations within each layer \(W_{L}\) can be condensed into a single layer with \(W = \prod_{L}W_{L}\). A single layered linear neural network is pretty limited.

Putting all of this together, we can interpret a conv-net as follows.
* Lets say we input a \(100 \times 100\) image to the conv net. The input tensor \(X\) can be thought of as a vector with 10000 basis. Each basis is representing some positional component in an image.
* We know that the very first conv layer learns edge detection templates. We can think of that layer as transforming positional basis vector to edge basis vector. In this space, the image is represented in a more meaningful way as a linear combination of edge like features. In this manner, ever layer _transforms_ the data into a more meaningful basis vector space, eventually leading to a basis vectors consisting of output categories.

== Motivation

In the current computational model, the output of a neuron is different even though \(X\) and \(W\) vectors perfectly align with each other but differ in magnitudes. 
If we consider a neuron as a fundamental template matching unit, then various magnitudes of \(X\) and \(W\) should yield the same output. It also _feels_ like a simplification because we are now effectively searching for a unit vector \(W\) confined to various rotations around the origin. If \(W\) can be represented in parametric form, we are searching for \(\theta \in [0, 360]\) as opposed to \(\w_{i}\) which can range from \([-\inf, +\inf]\). Even though both spaces are infinite, with a small enough discretization, the search space of \(\theta\) seems a lot smaller.

The proposal is simple. Each neuron should compute: \(Y = \frac{W.X}{|W||X|}\). From a layer perspective, instead of computing \(W \times X\) we are now computing \(\frac{W \times X}{|X|}\).
= Rotationally invariant neuron
:hp-tags: deep learning

This is a continuation from the first link:https://raghakot.github.io/2017/01/03/Exploring-alternative-neural-computational-models.html[post] on exporing alternative neural computational models. To recap quickly, a neuron is fundamentally acting as a pattern matching unit by computing the dot product \(W \cdot X\), which is equivalent to un-normalized cosine similarity between vectors \(W\) and \(X\).

This model of pattern matching is very naive, in a sense that it is not invariant to translations or rotations. Consider the following weight vector template (conv filter) corresponding to vertical edge pattern `|`:

\(W = \begin{bmatrix}
0.2 & 1.0 & 0.2\\ 
1.0 & 1.0 & 1.0\\
0.2 & 1.0 & 0.2 
\end{bmatrix} \)

[.text-center]
.Visual representation of \(W\) template
image::alt_neural2/vertical_line_filter.png[vertical_line_filter, 300]
{empty} +

When a neuron tries to match this pattern in a \(3 \times 3\) input image patch, it will only output a high value if a vertical edge is found in the center of the image patch. i.e., dot product is not invariant to shifts. My first thought was to use link:https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient[pearson coefficient] as it provides shift invariance. However, this not a problem in practice as the filter is slid across all possible \(3 \times 3\) patches within the input image.

[.text-center]
.Sliding filter over input image to generate the output activation area (image borrowed from link:http://intellabs.github.io/RiverTrail/tutorial/[river trail documentation])
image::alt_neural2/conv_illustration.png[conv_illustration, 400]
{empty} +

In a way, the sliding window operation is quite clever as it communicates information about _parts of the image_ matching filter template without increasing the number of _trainable_ parameters.

How about rotational invariance? We know that a lot of conv filters are identical, rotated by some non-random factor.

[.text-center]
.A few conv filters of a vggnet (image borrowed from keras link:https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html[blog post]). Notice how some filters are identical but rotated.
image::alt_neural2/conv_filters.jpg[conv_filters, 600]
{empty} +

